{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "key_classification_rnn.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "_2VQo4bajwUU"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hX4n9TsbGw-f"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "0nbI5DtDGw-i",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9TnJztDZGw-n"
      },
      "source": [
        "# Key classification with an RNN for Tensor Flow Lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lUWearf0Gw-p"
      },
      "source": [
        "Classify USB data which comes in packets of 8 bytes representing shift and key presses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_2VQo4bajwUU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z682XYsrjkY9",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow-text\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pRmMubr0jrE2"
      },
      "source": [
        "## Setup input pipeline\n",
        "\n",
        "Data for the pipeline needs to be in the form of a numpy array so we wrap our simple array in the call to np.array\n",
        "\n",
        "Todo: Generate this data some how."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SHRwRoP2nVHX",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "dataset = np.array([ [2,0,4,0,0,0,0,0],[2,0,4,0,0,0,0,0],[0,0,5,0,0,0,0,0]])  # The letter A with a shift\n",
        "resultset = np.array([[1,0],[1,0],[0,1]])\n",
        "\n",
        "for ex in dataset:\n",
        "  print(ex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GlYWqhTVlUyQ"
      },
      "source": [
        "## Prepare the data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiKPTKQRtH7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 50000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "#Cheating\n",
        "train_dataset= dataset\n",
        "test_dataset = dataset\n",
        "\n",
        "train_results = resultset\n",
        "test_results = resultset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9L8OQ5HVpwQ",
        "colab_type": "text"
      },
      "source": [
        "Lets take a look at one of these to see how it now looks "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vvru8bMikpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Batch shape:\", train_dataset.shape)\n",
        "print(\"label shape:\", train_results.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bjUqGVBxGw-t"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bgs6nnSTGw-t"
      },
      "source": [
        "Build a `tf.keras.Sequential` model\n",
        "\n",
        "Use the input_shape parameter so that the convertion process can work correctly\n",
        "\n",
        "A recurrent neural network (RNN) processes sequence input by iterating through the elements. RNNs pass the outputs from one timestep to their inputâ€”and then to the next.\n",
        "\n",
        "The `tf.keras.layers.Bidirectional` wrapper can also be used with an RNN layer. This propagates the input forward and backwards through the RNN layer and then concatenates the output. This helps the RNN to learn long range dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LwfoBkmRYcP3",
        "colab": {}
      },
      "source": [
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(16, activation='relu', input_shape=(8,)),\n",
        "  tf.keras.layers.Dense(2)\n",
        "  ])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-YfTajylxGY",
        "colab_type": "text"
      },
      "source": [
        "The optimiser used for compiling seems to affect what we get when we put it onto the Arduino, for examples am getting zeros and overflows rather than data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kj2xei41YZjC",
        "colab": {}
      },
      "source": [
        "#model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "model.compile (optimizer='rmsprop',\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "#              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "#              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zIwH3nto596k"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI5shHP1xfxA",
        "colab_type": "text"
      },
      "source": [
        "Training on a reduced data by using .take(20) on the batches and reducing the validation steps to speed verification of the technique. Can use the whole set once we know the process will work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hw86wWS4YgR2",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_dataset,train_results, epochs=1,\n",
        "                    validation_data=(test_dataset,test_results), \n",
        "                    validation_steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BaNbXi43YgUT",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0W_jiReyE0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model\n",
        "model.save(\"keyclassification_model\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ARZI6Ks_au",
        "colab_type": "text"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kFh4xLARucTy",
        "colab": {}
      },
      "source": [
        "# predict on a sample data\n",
        "\n",
        "res = model.predict(np.array([[2, 0, 4, 0, 0, 0, 0, 0],\n",
        "                              [0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                              [2, 0, 5, 6, 0, 0, 0, 0],\n",
        "                              [0,0,5,0,0,0,0,0]]))\n",
        "print(res)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yROjuhJYsxJw",
        "colab_type": "text"
      },
      "source": [
        "# Export the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQoXPUlhDbT3",
        "colab_type": "text"
      },
      "source": [
        "Convert the model to TFLite then format as a big C array.\n",
        "\n",
        "Based on https://github.com/eloquentarduino/tinymlgen/blob/master/tinymlgen/tinymlgen.py\n",
        "\n",
        "Ref https://blog.tensorflow.org/2019/06/tensorflow-integer-quantization.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbyfLSen6S8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install hexdump"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvWkC4zmPcdJ",
        "colab_type": "text"
      },
      "source": [
        "Did some experiments with the optimisations.\n",
        "\n",
        "```\n",
        "optimizers = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "```\n",
        "\n",
        "results in \n",
        "\n",
        "```\n",
        "Initialising...\n",
        "Type FLOAT16 (10) not is not supported\n",
        "Failed to initialize tensor 1\n",
        "MicroAllocator: Failed to initialize.\n",
        "AllocateTensors() failed\n",
        "```\n",
        "\n",
        "Tried also:\n",
        "\n",
        "```\n",
        "# From TinyML: Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power\n",
        "def representative_dataset_gen():\n",
        "    for value in test_dataset:\n",
        "        yield np.array(value,dtype=np.dtype((np.float32,8)),ndmin=2)\n",
        "\n",
        "...\n",
        "\n",
        "optimizers = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "```\n",
        "but could not work out how to get a generator to produce data in the right way\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcb13ix0DkJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Experimenting with optimisations\n",
        "\n",
        "import re\n",
        "import hexdump\n",
        "import tensorflow as tf\n",
        "\n",
        "def port(model,optimize=True, variable_name='model_data',pretty_print=False):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    if optimize:\n",
        "        if isinstance(optimize, bool):\n",
        "            optimizers = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "        else:\n",
        "            optimizers = optimize\n",
        "\n",
        "        converter.optimizations = optimizers\n",
        "    tflite_model = converter.convert()\n",
        "    bytes = hexdump.dump(tflite_model).split(' ')\n",
        "    c_array = ', '.join(['0x%02x' % int(byte, 16) for byte in bytes])\n",
        "    c = 'const unsigned char %s[] DATA_ALIGN_ATTRIBUTE = {%s};' % (variable_name, c_array)\n",
        "    if pretty_print:\n",
        "        c = c.replace('{', '{\\n\\t').replace('}', '\\n}')\n",
        "        c = re.sub(r'(0x..?, ){12}', lambda x: '%s\\n\\t' % x.group(0), c)\n",
        "    c += '\\nconst int %s_len = %d;' % (variable_name, len(bytes))\n",
        "    preamble = '''\n",
        "#ifdef __has_attribute\n",
        "#define HAVE_ATTRIBUTE(x) __has_attribute(x)\n",
        "#else\n",
        "#define HAVE_ATTRIBUTE(x) 0\n",
        "#endif\n",
        "#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__))\n",
        "#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4)))\n",
        "#else\n",
        "#define DATA_ALIGN_ATTRIBUTE\n",
        "#endif\n",
        "'''\n",
        "    return preamble + c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq-A2h4mD0jM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c_code = port(model,optimize=True,pretty_print=True)\n",
        "\n",
        "print(len(c_code))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIRo66RoTc-1",
        "colab_type": "text"
      },
      "source": [
        "File size needs to be < 400K to fit onto the device. Check the model_data_len value at the bottom of the file.\n",
        "const int model_data_len = 109840 and a tiny bit of code comes to 90% of the availabe space.\n",
        "But perhaps it also needs to be smaller than the available ram to be able to run? For example the sine model is just 2640 bytes;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UumRfLYuFBxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c_file = open(r\"text_model.h\",\"w+\")\n",
        "\n",
        "n = c_file.write(c_code)\n",
        "c_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8NgZhT8EaSc",
        "colab_type": "text"
      },
      "source": [
        "# Testing the TFLite model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2EKHsYKEm-w",
        "colab_type": "text"
      },
      "source": [
        "It is possible to reload the model back into the notebook and test it here.\n",
        "\n",
        "Arena Size?\n",
        "\n",
        "https://github.com/edgeimpulse/tflite-find-arena-size\n",
        "\n",
        "\n",
        "Debugging TFLite\n"
      ]
    }
  ]
}